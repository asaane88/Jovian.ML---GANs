{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "colab": {
      "name": "01-tensor-operations.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UpjdZ18-pHu"
      },
      "source": [
        "# Jovian Commit Essentials\n",
        "# Please retain and execute this cell without modifying the contents for `jovian.commit` to work\n",
        "!pip install jovian --upgrade -q\n",
        "import jovian\n",
        "jovian.utils.colab.set_colab_file_id('19Gx363j3wl5Y7rA9-zvPMDBAFzx1GE79')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5p9yFLXq-pID",
        "outputId": "6774ff70-3e61-44c8-a95e-cf04ff6ee8e3"
      },
      "source": [
        "# Windows\n",
        "!pip install numpy torch==1.7.0+cpu torchvision==0.8.1+cpu torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\r\n",
            "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (1.19.2)\r\n",
            "Requirement already satisfied: torch==1.7.0+cpu in /opt/conda/lib/python3.8/site-packages (1.7.0+cpu)\r\n",
            "Requirement already satisfied: torchvision==0.8.1+cpu in /opt/conda/lib/python3.8/site-packages (0.8.1+cpu)\r\n",
            "Requirement already satisfied: torchaudio==0.7.0 in /opt/conda/lib/python3.8/site-packages (0.7.0)\r\n",
            "Requirement already satisfied: future in /opt/conda/lib/python3.8/site-packages (from torch==1.7.0+cpu) (0.18.2)\r\n",
            "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch==1.7.0+cpu) (3.7.4.3)\r\n",
            "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.8/site-packages (from torch==1.7.0+cpu) (0.6)\r\n",
            "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.8/site-packages (from torchvision==0.8.1+cpu) (8.0.0)\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0NJi4Kn-pIH"
      },
      "source": [
        "# Import torch and other required modules\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxcWN7Cc-pII"
      },
      "source": [
        "## Function 1 - torch.tensor\n",
        "\n",
        "A tensor can be constructed from a Python list or sequence using the torch.tensor() constructor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAbWZwcA-pIJ",
        "outputId": "561dd2d2-7cbd-4d4c-8431-12776d4b4c52"
      },
      "source": [
        "# Example 1 - working (change this)\n",
        "torch.tensor([[1, 2, 3], [6., 5., 8.]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2., 3.],\n",
              "        [6., 5., 8.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5S1QbDHY-pIN"
      },
      "source": [
        "A torch.Tensor is a multi-dimensional matrix containing elements of a single data type (Ex. Float)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6c9GgjWW-pIO",
        "outputId": "61968a86-df68-48ab-8397-5ed2bd9db525"
      },
      "source": [
        "# Example 2 - working\n",
        "import numpy as np\n",
        "torch.tensor(np.array([[1, 2, 3], [6., 5., 8.]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2., 3.],\n",
              "        [6., 5., 8.]], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZT2fhGz-pIP"
      },
      "source": [
        "Tensors are similar to NumPyâ€™s ndarrays, with the addition being that Tensors can also be used on a GPU to accelerate computing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RhKZFT0-pIP",
        "outputId": "19df6a64-e96a-4581-a5fe-07998595e7b2"
      },
      "source": [
        "# Example 3 - breaking (to illustrate when it breaks)\n",
        "torch.tensor([[3, 5, 7, 8], [3, 4, 5]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "expected sequence of length 4 at dim 1 (got 3)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-1201ba9bba69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Example 3 - breaking (to illustrate when it breaks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: expected sequence of length 4 at dim 1 (got 3)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gyjGQFj-pIQ"
      },
      "source": [
        "Tensors can have any number of dimensions and different lengths along each dimension. We can inspect the length along each dimension using the .shape property of a tensor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRYjDi2L-pIR"
      },
      "source": [
        "A ValueError is thrown because the lengths of the rows [3, 5, 7, 8] and [3, 4, 5] don't match."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJKkSe4O-pIR"
      },
      "source": [
        "!pip install jovian --upgrade --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEcR4R8p-pIS"
      },
      "source": [
        "import jovian"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIAxKyJk-pIS",
        "outputId": "f71033d4-f697-490b-f21e-f71fe849f649"
      },
      "source": [
        "jovian.commit(project='01-tensor-operations')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[jovian] Attempting to save notebook..\u001b[0m\n",
            "[jovian] Updating notebook \"asaane88/01-tensor-operations\" on https://jovian.ai\u001b[0m\n",
            "[jovian] Uploading notebook..\u001b[0m\n",
            "[jovian] Uploading additional files...\u001b[0m\n",
            "[jovian] Committed successfully! https://jovian.ai/asaane88/01-tensor-operations\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://jovian.ai/asaane88/01-tensor-operations'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLrH_kbu-pIT"
      },
      "source": [
        "## Function 2 - torch.nn\n",
        "\n",
        "A fully-connected ReLU network with one hidden layer, trained to predict y from x by minimizing squared Euclidean distance.\n",
        "\n",
        "This implementation uses the nn package from PyTorch to build the network. The nn package defines a set of Modules, which you can think of as a neural network layer that has produces output from input and may have some trainable weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51G8VHhE-pIU"
      },
      "source": [
        "# Example 1 - working\n",
        "import torch\n",
        "\n",
        "N, D_in, H, D_out = 800, 9900, 1100, 2000\n",
        "\n",
        "x = torch.randn(N, D_in)\n",
        "y = torch.randn(N, D_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlrk55pk-pIU"
      },
      "source": [
        "1. N is batch size; D_in is input dimension;\n",
        "2. H is hidden dimension; D_out is output dimension.\n",
        "3. Create random Tensors to hold inputs and outputs (x and y)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvEGvXJX-pIV"
      },
      "source": [
        "# Example 2 - working\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(D_in, H),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(H, D_out),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5031db2U-pIV"
      },
      "source": [
        "1. Use the nn package to define our model as a sequence of layers. \n",
        "2. nn.Sequential is a Module which contains other Modules, and applies them in sequence to produce its output. \n",
        "3. Each Linear Module computes output from input using a linear function, and holds internal Tensors for its weight and bias."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlV9CFSH-pIW"
      },
      "source": [
        "# Example 3 - breaking (to illustrate when it breaks)\n",
        "loss_fn = torch.nn.MSELoss(reduction='sum')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gfg8To66-pIX"
      },
      "source": [
        "1. The nn package also contains definitions of popular loss functions; \n",
        "2. in this case we will use Mean Squared Error (MSE) as our loss function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Bm7pYRN-pIY",
        "outputId": "b95bad39-242f-4cd1-eef8-11a75044159f"
      },
      "source": [
        "jovian.commit(project='01-tensor-operations')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[jovian] Attempting to save notebook..\u001b[0m\n",
            "[jovian] Updating notebook \"asaane88/01-tensor-operations\" on https://jovian.ai\u001b[0m\n",
            "[jovian] Uploading notebook..\u001b[0m\n",
            "[jovian] Uploading additional files...\u001b[0m\n",
            "[jovian] Committed successfully! https://jovian.ai/asaane88/01-tensor-operations\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://jovian.ai/asaane88/01-tensor-operations'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZY64B4U-pIZ"
      },
      "source": [
        "## Function 3 - torch.hub\n",
        "\n",
        "Pytorch Hub is a pre-trained model repository designed to facilitate research reproducibility.\n",
        "\n",
        "Pytorch Hub supports publishing pre-trained models(model definitions and pre-trained weights) to a github repository by adding a simple hubconf.py file.\n",
        "\n",
        "hubconf.py can have multiple entrypoints. Each entrypoint is defined as a python function (example: a pre-trained model you want to publish)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HaP59pN-pIZ"
      },
      "source": [
        "# Example 1 - working\n",
        "dependencies = ['torch']\n",
        "from torchvision.models.resnet import resnet18 as _resnet18\n",
        "\n",
        "# Top level data directory. Here we assume the format of the directory conforms\n",
        "#   to the ImageFolder structure\n",
        "data_dir = \"/hymenoptera_data\"\n",
        "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
        "model_name = \"resnet\"\n",
        "# Number of classes in the dataset\n",
        "num_classes = 2\n",
        "# Batch size for training (change depending on how much memory you have)\n",
        "batch_size = 8\n",
        "# Number of epochs to train for\n",
        "num_epochs = 15\n",
        "# Flag for feature extracting. When False, we finetune the whole model,\n",
        "#   when True we only update the reshaped layer params\n",
        "feature_extract = True\n",
        "\n",
        "\n",
        "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
        "    # Initialize these variables which will be set in this if statement. Each of these\n",
        "    #   variables is model specific.\n",
        "    model_ft = None\n",
        "    input_size = 0\n",
        "\n",
        "    if model_name == \"resnet\":\n",
        "        \"\"\" Resnet18\n",
        "        \"\"\"\n",
        "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "        return model_ft, input_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhMqq65I-pIf"
      },
      "source": [
        "1. dependencies variable is a list of package names required to load the model.\n",
        "2. ResNet-18 is a convolutional neural network that is 18 layers deep. You can load a pretrained version of the network trained on more than a million images from the ImageNet database\n",
        "3. resnet18 is the name of entrypoint to create a hubconf.py file. \n",
        "4. args and kwargs are passed along to the real callable function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJxc595w-pIg"
      },
      "source": [
        "# Example 2 - working\n",
        "\n",
        "# Initialize the model for this run\n",
        "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
        "\n",
        "# Print the model we just instantiated\n",
        "print(model_ft)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5trmy34j-pIh"
      },
      "source": [
        "1. Call the model, load pretrained weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w62Wh6qi-pIh"
      },
      "source": [
        "# Example 3 - breaking (to illustrate when it breaks)\n",
        "if pretrained:\n",
        "    dirname = os.path.dirname(__file__)\n",
        "    checkpoint = os.path.join(dirname, <RELATIVE_PATH_TO_CHECKPOINT>)\n",
        "    state_dict = torch.load(checkpoint)\n",
        "    model.load_state_dict(state_dict)\n",
        "\n",
        "    checkpoint = 'https://download.pytorch.org/models/resnet18-5c106cde.pth'\n",
        "    model.load_state_dict(torch.hub.load_state_dict_from_url(checkpoint, progress=False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZTuGYff-pIi"
      },
      "source": [
        "1. For checkpoint saved in local github repo, e.g. <RELATIVE_PATH_TO_CHECKPOINT>=weights/save.pth\n",
        "2. For checkpoint saved elsewhere"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTEFDbne-pIk"
      },
      "source": [
        "In transfer learning, The performance of finetuning vs. feature extracting depends largely on the dataset but in general both transfer learning methods produce favorable results in terms of training time and overall accuracy versus a model trained from scratch. \n",
        "\n",
        "Pretrained Models can be used to reduce training time and achieve better results on large size image datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGefqGi5-pIl",
        "outputId": "48dc51c4-8d75-48c0-e129-91458529e4d1"
      },
      "source": [
        "jovian.commit(project='01-tensor-operations')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[jovian] Attempting to save notebook..\u001b[0m\n",
            "[jovian] Updating notebook \"asaane88/01-tensor-operations\" on https://jovian.ai\u001b[0m\n",
            "[jovian] Uploading notebook..\u001b[0m\n",
            "[jovian] Uploading additional files...\u001b[0m\n",
            "[jovian] Committed successfully! https://jovian.ai/asaane88/01-tensor-operations\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://jovian.ai/asaane88/01-tensor-operations'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lQXDw8Q-pIp"
      },
      "source": [
        "## Function 4 - torch.arange\n",
        "\n",
        "Returns a one dimension tensor with the parameters chosen: START, END (only one mandatory) and STEP."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdDRjpkI-pIq",
        "outputId": "e5374c6c-9dfc-49dc-d62a-e9db69a70bcd"
      },
      "source": [
        "# Example 1 - working\n",
        "torch.arange(8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4, 5, 6, 7])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KMzV7-y-pIr"
      },
      "source": [
        "Simple tensor created with only one argument (END) given. Therefore, START is by default 0 and the END is not included, we get up to 7 (END -1)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxnNEdTz-pIs"
      },
      "source": [
        "# Example 2 - working\n",
        "torch.arange(2, 100, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsF4MqLS-pIt"
      },
      "source": [
        "Tensor that starts with 2 (included), and the following values are added by 5 (STEP). until we reach 99 (END-1). Note that the last value won't be higher than END)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrdmgDy--pIu",
        "outputId": "6d6ddb90-db9a-4e4c-a1d2-20e933dba5b9"
      },
      "source": [
        "# Example 3 - breaking (to illustrate when it breaks)\n",
        "torch.arange(5, 3, 4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "upper bound and larger bound inconsistent with step sign",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-411c0e4dc2c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Example 3 - breaking (to illustrate when it breaks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: upper bound and larger bound inconsistent with step sign"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0864zdO6-pIv"
      },
      "source": [
        "In this simple example, when START is bigger than END, the spet sign must be negative in the sense that it is counting backwards."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZylVEve8-pIv"
      },
      "source": [
        "Closing comments about when to use this function:\n",
        "This simple function can be very useful to create Tensors of 1 dimensions and, if more dimensions are required, we can just create them withing the bigger one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGIFMrxv-pIw",
        "outputId": "f7214bff-703f-442c-8b3a-7aa978fee7e0"
      },
      "source": [
        "jovian.commit(project='01-tensor-operations')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[jovian] Attempting to save notebook..\u001b[0m\n",
            "[jovian] Updating notebook \"asaane88/01-tensor-operations\" on https://jovian.ai\u001b[0m\n",
            "[jovian] Uploading notebook..\u001b[0m\n",
            "[jovian] Uploading additional files...\u001b[0m\n",
            "[jovian] Committed successfully! https://jovian.ai/asaane88/01-tensor-operations\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://jovian.ai/asaane88/01-tensor-operations'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45vDA0rI-pIw"
      },
      "source": [
        "## Function 5 - torch.reshape\n",
        "\n",
        "Returns an specific shape for a tensor already created; it will have the same data as the original tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiW7peEN-pIx",
        "outputId": "c150fd3c-d9da-4739-daf7-584cb7eef08f"
      },
      "source": [
        "# Example 1 - working\n",
        "tensor3 = torch.arange(4.)\n",
        "torch.reshape(tensor3, (2,2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1.],\n",
              "        [2., 3.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5-YNXEl-pIx"
      },
      "source": [
        "First the tensor was created with the arange method (ergo, only 1 dimension).\n",
        "\n",
        "Then we RESHAPE it with the function and transformed it to a 2 x 2 matrix)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJKMogtp-pIy",
        "outputId": "b7f9e6b8-14ef-4239-944f-bc41cc549f9f"
      },
      "source": [
        "# Example 2 - working\n",
        "tensor4 = torch.arange(16,)\n",
        "torch.reshape(tensor4, (4, 4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  1,  2,  3],\n",
              "        [ 4,  5,  6,  7],\n",
              "        [ 8,  9, 10, 11],\n",
              "        [12, 13, 14, 15]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZpZsv5R-pIy"
      },
      "source": [
        "Same case as before, we just reshaped the tensor (tensor4) to a new more usable tensor with desired shape."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZWmqUqZ-pIz",
        "outputId": "ca7f0cd2-fe83-4ae2-ec08-0dfa19353c87"
      },
      "source": [
        "# Example 3 - breaking (to illustrate when it breaks)\n",
        "torch.reshape(tensor4, (3, 3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "shape '[3, 3]' is invalid for input of size 16",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-6e6d41901314>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Example 3 - breaking (to illustrate when it breaks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[3, 3]' is invalid for input of size 16"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNrXl5tD-pIz"
      },
      "source": [
        "Here we tried the same a before, however the shape designated to our original table does't match our original elements displayed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHrEz23L-pIz"
      },
      "source": [
        "This function is very powerful and it would surely help with handling of better information regarding children at the partk!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyX7xhbM-pI0",
        "outputId": "f42dc120-045e-4f67-b60a-63ef22371432"
      },
      "source": [
        "jovian.commit(project='01-tensor-operations')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[jovian] Attempting to save notebook..\u001b[0m\n",
            "[jovian] Updating notebook \"asaane88/01-tensor-operations\" on https://jovian.ai\u001b[0m\n",
            "[jovian] Uploading notebook..\u001b[0m\n",
            "[jovian] Uploading additional files...\u001b[0m\n",
            "[jovian] Committed successfully! https://jovian.ai/asaane88/01-tensor-operations\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://jovian.ai/asaane88/01-tensor-operations'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IB26QtKC-pI0"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "We covered tools that are simple yet very powerful and will help you during your study of PyTorch.\n",
        "\n",
        "You will be able to manipulate the Tensors as you which and be able to focus on the greater picture when learning deep process, without having to handle the hassle of hand-writing the Tensor themselves."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXSGdmA7-pI1"
      },
      "source": [
        "## Reference Links\n",
        "Provide links to your references and other interesting articles about tensors\n",
        "* Official documentation for tensor operations: https://pytorch.org/docs/stable/torch.html\n",
        "* ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZRT2dy--pI1",
        "outputId": "1e22acec-4037-4b39-8385-9ece070012da"
      },
      "source": [
        "jovian.commit(project='01-tensor-operations')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[jovian] Attempting to save notebook..\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FXd8gsk-pI2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}